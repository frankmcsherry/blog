# A decade in review (2015 - 2024)

This blog came into existence back in 2014, during a period of transition.
I had been laid off, as part of Microsoft's closure of their Silicon Valley research lab.
I had also decided not to take a new job (!!) and instead got a one-way ticket to Morocco (I had some professional obligations in Europe, but for Shengen reasons could only stay three months; plus: surfing and yoga!).
Perhaps most consequentially, I had also decided to pick up Rust, build up some new skills, and where appropriate tell folks about it.

Fun story, I was initially going to pick up Go, then an alternate up and coming "systems language".
My MSR-SVC colleagues have a certain style, helpful but not exactly supportive, and I was quickly linked [Why Go is not Good](https://yager.io/programming/go.html).
It all made a lot of sense, so I picked up Rust instead (which was then pre-1.0 and had no such post).
Playing that back, and given other choices like Nim, Swift, or Zig, I think I'd do it exactly the same way again.
2015 Rust worked great as a language for expressing myself to my laptop computer.

Speaking of which, the real protagonist in many of the stories over these years is an Apple MacBook Pro (Retina, 13-inch, Mid 2014).
Story-wise, that is getting ahead of ourselves though.

We'll cruise through the years in the context of the chronology provided at [the root of the blog](https://github.com/frankmcsherry/blog).
There will be some amount of personal reflection, some nostalgia, and potentially some character development.
There's certainly been a lot less sass of late, at least.

## Prologue: 2014

My [first post](https://github.com/frankmcsherry/blog/blob/master/posts/2014-12-15.md) was about "columnarization" and a Rust crate [columnar](https://github.com/frankmcsherry/columnar).
This also led to [my first Hacker News post](https://news.ycombinator.com/item?id=8768236), bickering because of course.
I said there might be character development, and .. spoilers .. we'll eventually to get to my last Hacker News post.
The post certainly set off a dopamine reward loop; I pushed it, got on a flight back home to VT for the holidays, and by the time my flight landed had several folks talking about it, and talking to me about interviews.
Too bad for them, I thought!

Other posts followed, including two rebooting my work on timely dataflow, but this time in Rust.
These posts set up the blog as almost a journal, explaining what I was doing in case anyone happened to find it interesting.
I have no evidence that this was the case, at least not on Hacker News.

And with that the year 2014 wrapped, and the decade began.

## 2015

The 2015 year started with a bang.
The academic computer science equivalent of a drive-by.

The COST paper was about how many big data systems are all overhead, and rarely get any faster than a laptop.
At least, not on the data sets that they use in the evaluations presented in papers.
That makes the papers not nearly as clever as folks thought they were, though (importantly) it doesn't mean the ideas are bad, just badly reasoned.

The [post announcing the COST work](https://github.com/frankmcsherry/blog/blob/master/posts/2015-01-15.md) blew up, on Twitter (RIP) and Hacker News (of course; it is "I'm smarter than you all" catnip).
It is still the thing that I appear to be best known for, which I am conflicted about.
Both that I did other neat things, and also that there are two other villianous co-authors who deserve credit as well.
A run of other posts, working the recurring COST trope that many academics (seemingly) couldn't tell good systems from bad.
I harbored a fantasy that this would change, but in classic Sci-Fi ending a literature search reveals that this same observation is made every five years or so, and then forgotten.

This is also the year that I head out from the United States, first to Morocco (no posts, only chill) and then to Berlin.
And then to the United Kingdom, and then to Switzerland.

Berlin was incredible.
I suspect you hear that from many folks, about many different places, but it's the same story.
I was personally very productive in the time, working out of [the betahaus cafe](https://www.betahaus.com), and occasionally dropping in on various data artisans.

I did a lot more work on dataflows timely and differential, and wrote (and [wrote about](https://github.com/frankmcsherry/blog/blob/master/posts/2015-05-04.md)) what may be my worst conceived Rust crate: `abomonation`.
The name is not a typo; it is what the first person to understand how it worked exclaimed about it, publicly, the moment they understood it.
It uses unsafe Rust code, which I 100% do not recommend.
Rust was at the time otherwise very explicit about what your program will do, and unsafe code up-ends this through the confounding factor of Rust's various and evolving side-hustles with LLVM.

In May I presented [the COST work at HotOS 2015](https://www.usenix.org/conference/hotos15/workshop-program/presentation/mcsherry), was invited to ETHZ in Zürich and accepted, and packed up from Berlin to head to the UK for a month.

I spent two weeks working with [Malte Schwarzkopf](https://cs.brown.edu/people/malte/), mostly trying out the Rust timely dataflow.
Fun humbling fact: if you have `p` processes each with `w` workers, you must multiply `p * w` rather than add them.
You only get so far testing things on a laptop.
But the work also led us to have a serious look at [network bloat in big data systems](https://github.com/frankmcsherry/blog/blob/master/posts/2015-07-08.md), through the lens of a critical look at a NSDI 2015 paper that said concluded that CPU was the bottleneck for big data systems.
We wrote up a blog post like real academics, and it ended up being the first (perhaps only?) blog post I've written that is cited in a published paper (by someone else).

ETH Zürich filled out the back half of the year, with one of my [more cherish sassy posts](https://github.com/frankmcsherry/blog/blob/master/posts/2015-08-20.md) about big data systems.
My understanding is that this led to a question being asked of an author at the conference, and raised questions more about how we conduct ourselves.
I think it's a great question to raise, whether we all pretend to the outside world that we are doing equally and unquestionably great work, or whether we reveal that probably none of us think that, and here are what the thoughts look like.
I also got in a trove of timely dataflow and differential dataflow posts, and wrote [an amazing paper](https://people.inf.ethz.ch/troscoe/pubs/chothia_vldb_2016.pdf) that I don't feel the world still has caught up to yet.

I also started to work with Andrea Lattuada, and despite me departing ETHZ at this time, I later returned in part because he was such a rewarding collaborator.
Some of the best work we did is still unpublished, but I'll get you a link in this post.

## 2016

In 2016 I'm back in Morocco, because I liked that a lot and wasn't coping great in Switzerland.

Reviewing the blog, 2016 seems to have been the year of [Differential Privacy](https://en.wikipedia.org/wiki/Differential_privacy#:~:text=Roughly%2C%20an%20algorithm%20is%20differentially,may%20be%20in%20a%20database.) for me.
The year starts with a ["tantrum" (as described by the subjects)](https://github.com/frankmcsherry/blog/blob/master/posts/2016-02-03.md), and continued in similar spirit [about the Usenix Security 2014 best paper](https://github.com/frankmcsherry/blog/blob/master/posts/2016-06-14.md) (it wasn't), find that a SIGMOD privacy theorem [wasn't actually true](https://github.com/frankmcsherry/blog/blob/master/posts/2016-08-16.md), and then has at a few other lesser papers.
These are pretty soft targets, as I've spent a lot of time thinking about differential privacy specifically, and as one of the crisper definitions (note: not necessarily better) it's fairly safely defensible.
We end up getting a prize or two for it later on.

Behind the scenes I'm still mostly doing Rust and dataflow work during this time.
My notes indicate [some Datalog work](https://github.com/frankmcsherry/blog/blob/master/posts/2016-06-21.md) (the laptop wins) and the start of [work on tracking motifs in evolving graphs](https://github.com/frankmcsherry/blog/blob/master/posts/2016-09-17.md), with Semih Salihoglu and Khaled Ammar.
The year ends with more time in Morocco, after which I apparently conclude I've had enough surfing and yoga, and do not return.

## 2017

The year of 2017 was the year of differential dataflow.
I started 2017 out in Valparaiso, which was fascinating but really not great (for me) as a non-Spanish speak.
The years work starts with a [status report on differential dataflow](https://github.com/frankmcsherry/blog/blob/master/posts/2017-02-11.md), lays out [a roadmap](https://github.com/frankmcsherry/blog/blob/master/posts/2017-03-28.md), and generally tries to think more clearly about what to do.
The year is also when I first seem to have landed upon [arrangements](https://github.com/frankmcsherry/blog/blob/master/posts/2017-05-01.md) as a way to organize data in differential dataflow.

Differential dataflow is for simplifying computation over continually changing data, and there is a recurring question of how to manage the accumulation of changes.
A not-unsurprising conclusion is that you might want a multi-version index, but building one requires threading a needle that trades off reads and writes, latency and throughput, all while maintaining a bounded footprint.
This work eventually led to a (imo strong) VLDB paper, though not without a bunch of mid reviews along the way.

I spent about half of the year in Vermont.
I'm returning to ETH Zürich, but the logicstics take half a year (vs one month, the previous time).
Vermont in the fall and winter is gorgeous, and I'd put that on repeat for the rest of my years if I could.
Days were alternately collecting berries, playing Breath of the Wild, and [writing about silly database papers](https://github.com/frankmcsherry/blog/blob/master/posts/2017-09-23.md).

## 2018

At the start of the year I'm now back in Zürich, working with the same group at ETH.
In particular, this is where I start working more deeply with Andrea Lattuada, Moritz Hoffmann, and Nikolas Goebel, among many others who are also great.

There are only ten posts for the year, but I think they are all bangers.
We have a return to form with [a deconstruction of an SOSP 2017 paper](https://github.com/frankmcsherry/blog/blob/master/posts/2018-02-11.md).
We have the breakdown of an [Uber privacy paper](https://github.com/frankmcsherry/blog/blob/master/posts/2018-02-25.md).
We have [a description of the most prolific Rust crate I've written](https://github.com/frankmcsherry/blog/blob/master/posts/2018-05-19.md): [`datafrog`](https://crates.io/crates/datafrog)(2.9M downloads and counting; but only because it is/was used by Polonius, I believe).
The year ends with me back in Vermont celebrating the holidays by [solving an otherwise fun puzzle using differential dataflow](https://github.com/frankmcsherry/blog/blob/master/posts/2018-12-30.md).

This year resulted in a large number of academic papers.
They weren't published this year, because that is rarely how academia works, but the work was largely completed in this year.
The work that was, for me, pleasant and thought provoking, as opposed to routing around hot takes from drive-by reviewers.

The [Shared Arrangements](https://people.inf.ethz.ch/troscoe/pubs/msherry-vldb-2020.pdf) paper is about modern differential dataflow, and the design behind its core data structure, the arrangement.
The tl;dr is that this is like a database index for streaming data-parallel systems.
There is a fair bit in the design and implementation to provide low latency and high throughput, for both reads and writes.
We ended up deleting a fair bit of the design discussion while iterating through submissions, and I'm not certain I like the final version more than the first versions.
At the same time, academic writing is very much not about me and what I want, which is in sharp contrast to blog writing.

The [Megaphone](https://arxiv.org/abs/1812.01371) paper shows that you can use timely dataflow coordination mechanisms to perform things as neat as live migration and reconfiguration.
Moments where you would otherwise need to pause the system can be handled by "virtually" cutting over from one configuration to another using the built in timestamps.
This would be a foundational insight that led to the use of [virtual time](https://dl.acm.org/doi/10.1145/3916.3988) as the coordinating principle at Materialize.

The [Timestamp Tokens](https://arxiv.org/pdf/2210.06113) paper never got published.
It was a solid fit for HotOS or CIDR, but not a "grown up" venue, and it turns out no one wanted to publish it.
But it's great, and you all should go and read it.
Of all the papers, this is the one closest to explaining what timely dataflow contributes.
I'm not about collecting publications, but it does feel bad that as one of the relatively few things I would *like* to publish, it hasn't been.

These papers were all the result of collaborations with great colleagues.
Most blog posts are not, with some exceptions, but these should remind you why we write longer form content, and the value of bringing together multiple people to form a joint understanding and presentation of bigger ideas.

The year ends with me in a rented car in Silicon Valley, with Arjun Narayan, trying to figure out who would want to fund a "Differential Dataflow, but with SQL" start up.

## 2019

The year starts with me working half time in Zürich.
I recommend this if you are in Switzerland: the country was more pleasant when I took long weekends hiking around in it, accepting rather than trying to understand why it felt so empty.

Around this point there was a resurgence of differential privacy chatter, as folks started to notice that the US Census was planning on using it, and that their use of it would interfere with their statistical work.
I recall some amount of these conversations happening on Twitter (RIP) with fewer academic publications to respond to.
Instead, we got a blog post rolling up [my confusion with Demography's poor understanding of privacy](https://github.com/frankmcsherry/blog/blob/master/posts/2019-04-12.md).

In May I land in New York City, as employee number five at Materialize, Inc.

This cuts in to the blogging for sure.
Materialize needs a variety of things at this point, many of which are not worth reporting on.
One notable exception was surfacing timely dataflow's introspection data as relational data, allow you to [interactively interrogate the system performance](https://github.com/frankmcsherry/blog/blob/master/posts/2019-08-03.md).

We have a post on what I think is the best benchmark, [LDBC](https://ldbcouncil.org), showing off [how one of its more challenging queries](https://github.com/frankmcsherry/blog/blob/master/posts/2019-06-13.md) can be handled by differential dataflow.
The benchmark got a bit weaker in the meantime, probably because no one likes benchmarks they are bad at (I do. I LOVE them).
Progress is only going to happen in this space by calling out the things we are bad at, which isn't as great for doing business.
I also went to SIGMOD and got a Test of Time award for [PINQ](https://css.csail.mit.edu/6.5660/2024/readings/pinq.pdf), hung out with various SIGMOD folks in a low-stress setting (e.g. Peter Boncz, Gabor Szarnyas), and got a chance to [write about big Datalog systems](https://github.com/frankmcsherry/blog/blob/master/posts/2019-09-06.md).

## 2020

You may recall that this year was a bit of a dumpster fire.

On March 16 I was writing about [processing taxi data in Materialize](https://github.com/frankmcsherry/blog/blob/master/posts/2020-03-16.md).
On March 20 I was in a rental car heading to the frost-blasted fields of Vermont to shelter in a winterized family summer home.

The posts and work in this time were more about staying happy, and working on things I liked.
We've got a lot more posts about Materialize, how SQL connects to dataflow, and how you can do weird and interesting things using SQL rather than Rust.

As one example, the `LATERAL` keyword in SQL allows you to hand-roll a subquery.
But it's also a great way to implement something like [prepared statements](https://en.wikipedia.org/wiki/Prepared_statement) in a dataflow system.
You build a SQL query that laterally joins the arguments of the prepared statement with the business logic, and the dataflow that results gets everything that it can done ahead of time, and responds to changes to your argument sets.
Bonus: your arguments not only produce answers to queries, but you get the changelog out as well.
Writing about [stuff like this](https://github.com/frankmcsherry/blog/blob/master/posts/2020-08-13.md), where you see new ways to hold existing tools, really works for me.

This is also the first time we get to really see the benefits of shared arrangements, in [how Materialize handles joins](https://github.com/frankmcsherry/blog/blob/master/posts/2020-11-18.md).
Pre-building the arrangements (think "indexes") results in a very low marginal cost of new queries.
Even though they join large collections of data, those collections already exist arranged, and the queries may not need to maintain any *additional* data.

## 2021

There are only three posts for this year.

Reading them, I can see why.
There's one good point, about [temporal filters](https://github.com/frankmcsherry/blog/blob/master/posts/2021-02-11.md).
These are a major unlock for bringing streaming and SQL together: you can write things like
```sql
SELECT * FROM my_data
WHERE mz_now() BETWEEN insert_ms AND delete_ms;
```
The hook here is that even for data that do not change, one can turn things on their head and reason about how queries might change as a result of `mz_now()`, time, changing.
The above maintains the data that are currently valid, with each record entering and dropping out at exactly the prescribed moments.

Towards the end of 2021 I am returning to NYC.

## 2022

This was a working year at Materialize.
Only three personal blog posts.

A fair bit of effort went in to Materialize's re-architecture as a scalable platform (from a single binary).
I don't seem to have blogged personally about this, but you can read about it [on the Materialize blog](https://materialize.com/blog/materialize-unbundled/).
I had a bit of existential angst about where I should be publishing things, wanting to avoid harvesting eyeballs for personal glory.
There are other [good posts](https://materialize.com/blog/virtual-time-consistency-scalability/) I've written there, as well as some bad ones.

By the end of the year, we have [recursion in Materialize](https://github.com/frankmcsherry/blog/blob/master/posts/2022-12-25.md).
In preview, at least.

## 2023 

We're up to eight posts this year.

I had a brief stint as "Head of Product" when we realized we needed more of that.
It concluded when the larger organization realized they needed less of me in that role.
But it did usher in a lot more "product thinking".
This is when I started to grind through Marty Cagan's books, Rumelt's "Good Strategy / Bad Strategy", and generally realized that most of our problems aren't technical problems as much as process problems.

There's not much to write about this, as you are *much* better served by reading from real practitioners in the space, rather than dilletantes like myself.
But I really do recommend you read, because understanding the challenges was a valuable part of me unlocking what the real problems I was looking at were, and how to take a swing at fixing them rather than just being frustrated.
That's not to say that things always worked out; people and process are harder than Rust and big data (which are really easy; is the secret).

I did a series on [Materialize's Product Principles](https://github.com/frankmcsherry/blog/blob/master/posts/2023-09-17.md).
This was surprisingly effective at making headway internally, as although they had been written down and communicated before, publishing them resonated with several folks, and that served to lock them in more than any Notion doc or empassioned Slack over would.
The work slowed down as I realized that we didn't always live up to these principles, and I wanted to fix that before smugly announcing how great we were.

I spent December 2023 doing [all of the Advent of Code problems in SQL](https://github.com/frankmcsherry/blog/blob/master/posts/2024-01-02.md).
This was exhausting, but also exhilarating.
Each got done on the day it was published, and with a few exceptions was a total pain in the posterior.
Nothing clarifies how not-great a chef you are as much as having to eat your own food for a month, where someone else picks the menu.
But, I think this is great.
No progress happens without clarity around your limitations and shortcomings.
You get to decide what to do about them, but you should at least be clear.

## 2024

This brings us to 2024, this year.

Statistically minded folks might realize that there are only a two posts until August, at which point there are lots.
I took some time off in August (two weeks, which written down doesn't actually feel like a lot), to see if some unhappiness was fundamentally about me, or the way I was working.
Good news: I wasn't fundamentally unhappy, just not working on anything I enjoyed for half a year.

But in August that unlocks.
I think in the two weeks I did about five different whole projects, and only managed to write about a few of them, but golly gee was there a bunch of pent up work.

1. The `columnar` crate that we started with plays a central role, as a safe approach to efficient memory layout and zero-copy serialization.
I'm really pleased with this work at the moment, as it brings together some optimism about the best parts of Rust, and making systems better, and delivering value for Materialize.
I've got more to write about that, as I'm still learning by doing, but there are worse things to do than [start here](https://github.com/frankmcsherry/blog/blob/master/posts/2024-08-24.md).

2. A timely dataflow user prompted me to look into WASM, and in particular running timely on WASM.
It turns out it is very close, and they had a PR that set it up to work (you have to unhook access to the clock).
Some modifications later, and the whole of timely is ready to have Rust's `std::time` be an optional thing.
This strikes me as very neat, because it is a clear way to demonstrate that there are no random timers or timeouts in the system.
Although *timely* dataflow, it is your notion of time rather than your computer's notion of time.

3. At the same time, the `columnar` work meant that it would now be quite cheap to move structured data between Rust and a WASM runtime like `wasmtime`.
It took a bit of learning to figure out how this happens, but Github Copilot was stellar here, and it was not too much work to get [a prototype up](https://github.com/frankmcsherry/blog/blob/master/posts/2024-10-11.md) that could run WASM operator in timely dataflow.
I'm not certain where this goes, because while WASM is fun, databases are not about fun, and they are almost certainly not about injecting your own code into SQL and watching it crash horribly and then terminating your contract.
No one wants that, except maybe the "WASM" and "fun" parts.

4. I thought I would learn Forth, but instead I learned [Joy](https://hypercubed.github.io/joy/html/j05cmp.html).
This is a sweet stack oriented language that isn't quite as close to the metal as Forth, but I found very pleasant to implement, and understand.
I have a few hundred lines of code that build up from almost zero (an allocator, some types) into a small language that I can write cutesy programs in.
I think everyone else probably did this much earlier in their career, perhaps as an undergraduate, but I never did.
I hope to write about this at some point, but I'm not sure what I'd say that hasn't been written by Joy's author (RIP).

5. I was frustrated by how Materialize's optimizer worked (more specifically, moments when it didn't) and [dove into e-graphs](https://github.com/frankmcsherry/blog/blob/master/posts/2024-10-19.md).
These are amazing, and while they aren't 100% fully general yet (as far as I can tell), they unlock much more broad thinking about how I understand programs (or, expressions at least).
I really enjoyed reading the paper, and writing my own version to learn even more (it's not so hard!)

So, that was about two weeks.
Oh boy was that refreshing.
Also I went to Paris and strolled around and slept, and generally had a nice time.
I recommend making sure you have a nice time, because I think I screwed that up for a few years.

With the year ending, most of the work now is on integrating `columnar` more with timely and differential.
This, with Moritz Hoffmann, has straightened out a bunch of thinking, and again brings me optimism about how things might be in the near future.
Parts fit together nicely, or when they don't they call to be straightened out so that they fit.
It feels good.

## 2025

This part hasn't happened yet, but I'm various amounts of optimistic for it.

Technically, there are lots of great options in front of me to play with.
This is personally satisfying, but a great many of them also dovetail together, and speak to practical concerns in products I'm working on.
Six months ago if you had asked what I want to do next I might have said "not this", but that has ticked upward dramatically since then.

Professionally, Materialize is inching towards product market fit.
So many people say they want it, people who use it say its amazing, and the potential is clearly there.
We still have a bit of dialing in to do, where retrospectively obvious omissions block folks at critical moments, or seemingly sensible tactical choices meant we locked out our biggest supporters.
We'll dial those in, though.

Personally, the past five years have been with a stellar partner that I haven't blogged about.
Not much to say here, other than I recommend this more than anything else over the past ten years, and wouldn't trade it away for anything.
In fact, I *would* trade away most of the other stuff for this.

Blogging remains therapeutic more than a killer way to have pronounced impact, and I'm going to keep doing it under that framing.
I'm torn between "write like no one is reading" and "write what you would want to read".
But I do recommend you write, if that helps you, as sharing what you've done with others is a quantum level up from doing the work in the first place.