# Evaluating Datatoad

Let's evaluate the performance of [datatoad](https://github.com/frankmcsherry/datatoad)!

In my experience, little is better for improving the performance of a system than forcing its evaluation on problems and datasets you don't control.
It's easy enough to make things go fast on that one problem you care about, but surprising and often irritating when it turns out this doesn't generalize.
In fact, we're going to do that right now!
We'll use a recent evaluation to see where datatoad falls down, where its performance could be improved, and perhaps where it already shines.

This has already resulted in some dramatic improvements!

Big thanks to the FlowLog folks, for putting together the problems, the datasets, and performing the evaluation for the other systems.
Evaluation can be hard and thankless work, and I appreciate it!
I'm mooching off of their work to improve my side-project, which doesn't feel fair.

## Evaluation

We're going to lean on an evaluation from the upcoming [FlowLog paper](https://arxiv.org/pdf/2511.00865), to appear at VLDB 2026.
They have put together a new Datalog engine, built over differential dataflow (full disclosure: I am delighted).
For their evaluation, they cover a large number of tasks and datasets, from "easy" to "hard", and "small" to "large".
They compare several systems, of course FlowLog, but also Souffl√©, RecStep, DDlog, DuckDB, and Umbra.
For each problem and dataset, they evaluate each system on 4- and 64-cores, and highlight the top performer in each configuration.

We're going to aim datatoad at the same problems and datasets, and compare against the top performer in each of the 4- and 64-core configurations.
The top performer is often FlowLog, but there are many good showings from the other systems in various settings as well.
We aren't going to use the same hardware, but if it turns out that dual "AMD EPYC 7543" CPUs is a soft target we may need to shade the enthusiasm a bit.
At the same time, the price on the internet for just one seems to be more than my entire laptop (a M2 MacBook Air).

In the charts below there are some special indicators:
* **X**: datatoad doesn't support aggregations.
* **TO**: the system didn't complete in under 900s.
* **?**: datatoad doesn't support antijoins and inequalities, but should soon.

Also, I've broken out datatoad's time to "load" the dataset and "exec" the query.
You should add these together before comparing against the "best-4" and "best-64" numbers, which are reported as a sum of the two.
As you'll see, the loading can often be dramatic, as it involves a bunch of CSV parsing (waste!) and index building (useful!).

I should also caveat that other than `galen` and the `tc`/`sc` computations, I haven't checked that the results are correct.
I should be able to for `csda` and `cspa`, but I'll likely need to reach out to the FlowLog folks about validation for other problems.

| problem   | dataset   | load  | exec  | best-4    | best-64   |
| ---------:| ---------:| -----:| -----:| ---------:| ---------:|
| cc        | **ALL**   |       | **X** |         - |         - |
| reach     |livejournal|  4.8s |  1.1s |      6.7s |      5.1s |
| reach     | orkut     |  7.8s |  1.3s |     11.0s |      8.6s |
| reach     | arabic    | 46.2s | 11.7s |     60.4s |     35.0s |
| reach     | twitter   |132.3s | 26.3s |    121.6s |     62.9s |
| sssp      | **ALL**   |       | **X** |         - |         - |
| transclos | G10k-0.001|  0.0s | 25.4s |     23.1s |      6.1s |
| transclos | G20k-0.001|  0.0s |243.3s |    542.8s |     42.4s |
| transclos | G40k-0.001|  0.1s |**TO** |    **TO** |    305.6s |
| samegen   | G10k-0.001|  0.0s | 45.8s |    177.6s |     18.6s |
| samegen   | G20k-0.001|  0.0s |411.1s |    **TO** |     90.7s |
| samegen   | G40k-0.001|  0.1s |**TO** |    **TO** |    815.9s |
| bipartite | roadca    |  0.4s |  1.4s |      3.5s |      1.3s |
| bipartite | netflix   |  7.4s | 11.3s |     12.1s |      8.0s |
| bipartite | mag       | 78.7s |**TO** |    167.9s |     76.7s |
| CSDA      | httpd     |  0.7s |  1.6s |      4.1s |      1.3s |
| CSDA      | linux     |  3.1s | 11.9s |     22.5s |      6.4s |
| CSDA      | postgresql|  2.5s |  5.8s |     11.4s |      4.9s |
| CSPA      | httpd     |  0.1s | 27.9s |     67.8s |     14.4s |
| CSPA      | linux     |  0.6s |  8.3s |     20.9s |      4.8s |
| CSPA      | postgresql|  0.3s | 29.8s |     76.7s |     15.0s |
| Andersen  | medium    |  2.8s |  2.2s |      7.9s |      4.2s |
| Andersen  | large     |  5.5s |  4.6s |     16.0s |      5.7s |
| Dyck      | kernel    |  0.9s |  2.0s |      5.0s |      1.4s |
| Dyck      | postgresql|  0.4s |  1.4s |      3.8s |      0.9s |
| Galen     | galen     |  0.1s | 11.9s |     32.2s |      8.7s |
| CRDT      | **ALL**   |       | **?** |         - |         - |
| Polonius  | **ALL**   |       | **?** |         - |         - |
| DDISASM   | **ALL**   |       | **?** |         - |         - |
| DOOP      | **ALL**   |       | **?** |         - |         - |

With the caveat that we don't yet know if the results are correct, datatoad would be in the running for fastest 4-core system on many of these problems, but doesn't really menace the 64-core numbers.
It is also a fair bit cheaper to run, and I suspect quite a lot simpler than many of the top systems.
All pending the outputs actually being correct, of course.

It also can't run many of the problems, which is worth saying out loud.

## Reflections

You are actually seeing the numbers after a bit of improvements were made.
I'd love to show you the numbers before, but .. in many cases they were essentially time outs.
But they were all teachable moments, and some of them are still in effect in the data above!

### Biting off too much can OOM

There were a few moments in datatoad where it decided it would do quite a lot of work, and materialize more data in memory than it should have.
There were two flavors here, with different backstories, but the same resolution.

1.  When joining we may "over-derive", producing a large number of instances of facts that deduplicate down to a smaller number.
    This is especially bad for the `tc` and `sg` problems, whose intermediate results are orders of magnitude larger than their deduplicated results.
2.  When loading `u32` data we have a roughly 12x memory overhead, which feels terrible to type out.
    There are just a pile of various lists of indexes and such, which could certainly be optimized but will always exist in some capacity.

Both cases share a common fix: don't try to do everything at once.
Rather than do all the work all at once, each of these moments (and a few others) benefit from imposing a limit on the tuples to produce at once (currently: 100M), and doing the work each time this limit is hit and merging the results together.
Fortunatelly, the log-structured merge idiom datatoad uses makes this change an easy one to adopt.

The result is substantially less memory used, and timely completion of hard tasks rather than sputtering with exhausted memory.
Slow tasks like 3600s for `bipartite mag` are seemingly due to memory exhaustion (paging), and indicate other moments where memory should be reined in.

### Data loading can be very slow

datatoad conventially loads data with a `.load` command that takes a regular expression and a filename.
Each line is matched against the expression, and the captures are extracted as the terms in the relation.
For example, here is how you might read two four-byte entries out of a tab-delimited file.
```
.load p (?<u32_foo>[^\t]+)\t(?<u32_bar>[^\t]+) ./CA-HepTh.txt
```

The generality of regular expressions helps run workloads without making "data reformating" part of the workflow.
Unfortunately, it also dramatically disadvantages systems that use it rather than customized loaders.

I added a `.flow` command that is like `.load` except it bakes in the idea that each line will be comma-separated, and all values are 32bit integer identifiers.
If it turns out this is wrong it's easy enough to change, but it felt bad having the general purpose `.load` repeatedly lose to what I imagine are specialized CSV loaders.

The data loading times are a bit suss generally, in my opinion.
For example, the `twitter` dataset is ~25GB of textual CSV, and the 132.3s datatoad takes to load them is putting them back in their 6GB row-major binary format that the could have been distributed in.
The remaining 26.3s of computation is more than twice as fast as the fastest 64-core number, which the FlowLog folks break down as also mostly due to data loading.
If you look only at post-loading execution, on 64 cores FlowLog is the fastest with only 17.5s, but appears slower than DuckDB at 44.8s but which has what seems like a sweet CSV loader.
Great to break the numbers apart, though candidly I'm most interested in the compute numbers.

### Query plans for `bipartite` are bad

Yeah it turns out that the bipartite problem reveals some planning glitches!

When have a semijoin like `foo(a, b), bar(b)`, datatoad does a bad job.
Rather than invoke an index on `foo` by `b`, it kicks things off with a bespoke shuffle of all of `foo`.
The index **is** needed, the planner just isn't thinking far enough ahead to realize this and does the work multiple times.
It turns out that the bespoke shuffle also has the "bites off too much" problem mentioned above, and each of the problems use much more memory than they should.
It should be fixed.

Not much more to say until I fix this, but it's a great example of how when other folks choose the problems, you learn a lot more about the limitations.

### Query literals aren't there yet

The Dyck problem is broken for me because where it ingests `0u32` and `1u32` literals from the inputs, I don't know that I can put these literals in a datatoad program.
We use `str` literals, rather than `[u8]` literals, for the obvious data entry reasons.
At the same time, this means that you can't match all byte-slice literals that could come from input files.

Not so surprising in retrospect, but I will need to ponder a way to resolve these.

**Update**: Fixed, by changing from `&str` query literals to hex encodings of bytes.
No one wants to type hex, of course, but it allows entry of all permitted byte patterns.
We'll make it more pleasant in the future with a layer higher up.

### Is datatoad amazing?

The numbers are small, but it's worth calling out that it doesn't do anything other than Datalog.

The other systems being studied do a lot of different things, one of which is Datalog.
DuckDB and Umbra support most of the generality of SQL, and likely wipe the mat with folks if the problem is something more analytics-shaped.
FlowLog and DDlog are both based on differential dataflow, which is fairly general itself.
These other systems have more to think about, and when you just have one job (Datalog) it's easier to get sweet looking numbers.

Also if you don't check the correctness of the results.

## Up next

I'm certainly going to study the results a fair bit more.

This work was kicked off because I introduced initial support for antijoins and the structure for function-based predicates (e.g. `x < y`, but also `x <= y < z`, `x + y = z`, and other "function-backed relations").
Many of the problems towards the bottom of the list rely on both antijoins and inequalities, and I'll need to implement them correctly to even see numbers.
But also, they'll (I hope) also call out challenges with planning these types of relations (they are fundamentally different, in that they have opinions but rarely propose values themselves).

I haven't confirmed that the computations are correct yet, and I'll need that information sooner than later.
It's obviously crucial for benchmarks in the first place, but also developing antijoins and other unbounded relations really wants to refer to a source of truth before feeling too clever.

Part of me really wants to parallelize datatoad, because it's clear that it would move the needle tremendously, and lines up with architectural choices (e.g. immutable LSMs, vs mutable b-trees).
I would like to do this at some point, but I figure I should try and get the other newer ideas out first, vs repeating the big hits from prior work.
But it should parallelize pretty nicely.
