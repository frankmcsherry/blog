# Differential dataflow internals; a work in progress

This post is really meant to be a series of posts about how to represent data managed in differential dataflow. As they are topically related and meant to build upon one another, I thought putting them in one place would help record and explain what I was thinking when implementing them.

In the spirit of "append only updates", this post will largely be append-only (modulo errors, edits). I'm also going to try and make the development process largely append-only as well: new implementations will be added to older ones, rather than replacing them, allowing us to keep track of where we were and how far we've come. This will probably break at various points, but that is the intent!

This series is going to start out intentionally pedantic and simple, to frame the problem in the simplest language and implementations. We will try and become smarter as we move along, but let's start with simple, and evaluate things as we go. Here is the planned roadmap:

* [Part 0/x: Trait definitions; defining what we require.]()

* Part 1/x: A very naïve implementation based on sorted lists.

* Part 2/x: Organizing the data into tries.

* Part 3/x: Adding an index.

* Part 4/x: ...

## Part 0: Trait definitions; defining what we require.

One of the things I like doing most when writing Rust code is to write trait definitions. These are the "interfaces" of Rust, which indicate the methods and types and such required in order to actually implement "a thing". For example, we are going to spend some time defining and implementing collections, and we need to specify what methods and such these collections need to provide to be generally useful.

One nice aspect of Rust is that just writing trait definitions gives you some insight into how your implementations are going to need to work. For example, all methods in Rust clearly indicate the *ownership* of input arguments and returned output. Ownership distinguishes between variable bindings that *own* the data, and can do pretty much whatever with it (including de-allocating it), and variable bindings that only *reference* the data (the sigil `&` indicates references at work). Just writing down the method signatures gives some clarity about which types own which data, who gets to refer to them, and for how long they will be around. Each of these decisions constrains your implementation, and even at this point it helps you think out which details implementations should commit to, and which they should be able to hide.

### An example trait definition

Let's try out a trait definition for the "collection trace" functionality, something that differential dataflow uses. In order to not make you angry with details I'm not going to start with the final version. I hope this ends up clearer than otherwise, and I suspect once you see the result you may agree.

Our collection trace tracks tuples `(key, val, time, delta)` of type `(Key, Val, Time, isize)` where the types `Key`, `Val`, and `Time` get to be chosen by the person who is instantiating our type. These generic parameters are indicated in the name of the trait, written as part of its definition as:

```rust
pub trait Trace<Key, Val, Time> {

	// methods and stuff goes here

}
```

In fact our trace is not going to work for any arbitrary types; there are constraints that the types need to satisfy. For example, if we want to find keys we had best be able to test keys for equality, right? Equality testing is defined by a trait, `Eq`. We can add the constraint that whichever type `Key` gets chosen implements equality testing by adding a constraint:

```rust
pub trait Trace<Key: Eq, Val, Time> {

	// methods and stuff goes here

}
```

See how we added `: Eq` after `Key`? That means that the choice of `Key` needs to also implement the trait `Eq`, which is great to know because from this point forward we can rely on it being true, and write things like `if key1 == key2` without knowing yet which types of key we will need to use.

Our trace actually has different constraints; the keys and values are going to be *ordered*, and the times must form [a lattice](https://github.com/frankmcsherry/differential-dataflow/blob/82783d89405ed28658c6c25c98d30750dd05c2ac/src/lattice.rs#L3-L28), which is like a not-exactly-ordered set (it is a partially ordered set with some additional structure).

```rust
pub trait Trace<Key: Ord, Val: Ord, Time: Lattice> {

	// methods and stuff goes here

}
```

Even just writing this much is helpful, because we have sorted out (or started too, at least) what needs to be true about the types we'll use.

### How about adding some methods? 

Yes, let's add some methods. There are two things most collections do: add data and get data. I'm going to write some over-simple versions of these that would be great, but lack some flexibility. Our data happens to be tuples `(key,val,time,delta)`, so we are going to add and retrieve vectors of those.


```rust
pub trait Trace<Key: Ord, Val: Ord, Time: Lattice> {

	/// incorporates a new bunch of differences into the trace.
	fn add(&mut self, diffs: Vec<(Key, Val, Time, isize))>);

	/// retrieves differences associated with a specified key.
	fn get(&mut self, key: &Key) -> Vec<(Key, Val, Time, isize)>;

}
```

You may notice the `&` sigil hanging around in a few places. We will get to that, but what it is saying is that when we call `add` or `get`, we are only temporarily working with `self`, the trace. Once the method returns, control of `self` returns too. Similarly, the use of `key` is only temporary access to the key. 

This contrasts with `diffs` in `add`: there is no `&` in front of the type, which means that `diffs` is actually an *owned* vector; we get to do whatever we want with it (add things to it, de-allocate it, etc). This ownership is pretty handy, because it is transitive: `diffs` also owns all of the contents of the vector, meaning all those keys and values and times and stuff. We'll want to put those in our collection!

Looks pretty good! What's not to like? Well, there are a few things. 

### Type parameters: letting the user choose

Adding and returning vectors is not unreasonable, but putting that detail in the trait definition limits our implementations. Does `add` really need the results to be materialized in a vector, and does `get` really need to allocate and return ownership of memory?

Not really. I mean, they could and that might be useful, but we could be more general by indicating that all `add` really needs is a way to enumerate the items you would like to add, and all `get` really needs to return is a way for you to enumerate the results. These could be backed by vectors, but they don't have to be. There will be better choices, it will turn out.

We have already seen the techniques that we will use to improve the `add` method: generic type parameters. The method can introduce a new generic type parameter, `Iter`, whose only requirement is that it implements the `Iterator` trait with appropriately typed items, and then accepts `diffs` as an `Iter` rather than a vector:

```rust
pub trait Trace<Key: Ord, Val: Ord, Time: Lattice> {

	/// incorporates a new bunch of differences into the trace.
	fn add<Iter: Iterator<Item=(Key, Val, Time, isize)>(&mut self, diffs: Iter);

	/// retrieves differences associated with a specified key.
	fn get(&mut self, key: &Key) -> Vec<(Key, Val, Time, isize)>;

}
```

All that we have done here is said that when one implements `add` one needs to be able to respond to arbitrary iterator types, without relying at all on the concrete type (no `Vec`-specific methods, for example). This has the advantage that when we *use* the method, we can use whatever iterators we like, including ones that don't stage the results in one vector before inserting them (e.g., timely dataflow delivers messages as small batches, and we may want to insert the results of concatenating all of these, without copying them to another location in memory first).

Before you get all "lol iterators", these type constraints mean that methods are available statically, and can be compiled down to roughly the sort of for-loops you would write by hand. Some times they are even better (some times they are worse). But, there are real performance differences between an iterator that reads a list of block of data, and an implementation that first copies them to a second contiguous allocation.

### Associated types: letting the implementation decide

What if the `get` method wants to return an iterator, but be coy about which specific iterator type it returns? It doesn't really make sense for the user to ask for an iterator type, because it is the implementation that has to determine what gets returned. Rather, it makes sense for the implementation to define the type of the result.

In Rust traits may define "associated types", which are a bit dual to the generic type parameters that users get to specify. These are types that the implementor of the trait determines, and other than constraints on the types nothing else is exposed through the interface of the trait. We can indicate that an implementor of `Trace` must name a type for the output of `get` and that this type must implement the `Iterator` trait with approriate items, just like so:

```rust
pub trait Trace<Key: Ord, Val: Ord, Time: Lattice> {

	/// incorporates a new bunch of differences into the trace.
	fn add<Iter: Iterator<Item=(Key, Val, Time, isize)>(&mut self, diffs: Iter);

	/// An iterator defined by the implementation to produce results.
	type OutputIterator: Iterator<Item=(Key, Val, Time, isize)>;

	/// retrieves differences associated with a specified key.
	fn get(&mut self, key: &Key) -> Self::OutputIterator;

}
```

Notice how `get` now returns `Self::OutputIterator`, a type totally unknown to us at this point, with only the promise that any implementor of `Trace` will need to be more specific. That's fine, we can be more specific when we implement things, and Rust can stitch everything together then. The flexibility the implementors get to choose different iterator implementations is great, though.

### Returning references: learning about lifetimes

Ok, brace yourselves.

The signatures of the methods have so-far involved *owned* data. When `get` returns an iterator whose items are tuples `(key, val, time, isize)` it yields tuples whose contents are owned by the recipient. That is great for the recipient, who can now do whatever they like with the results, but it can be expensive and restrictive for the implementation.

To make this more concrete, imagine that the key type is `u64` and the value type is `String`. A `String` is dynamically sized, depending on how much stuff you stuck in there. That means that a `String` involves some dynamically allocated memory, which is usually a bit annoying to go and grab more of when you don't need to. But, through our signatures we have promised to return actual *owned* `String` types, meaning the responsibility for the memory involved is passed from the trace implementation to the recipient. Unless the trace is getting rid of its copy of the string (no) it probably needs to make a copy, because you might decide to call `.all_caps()` on it.

If the recipient (you) just needed to *look* at the `String`, you might feel a bit silly for forcing all these allocations just to subsequently de-allocate them.

This is where Rust's references come in. References are not owned data, but rather "references" to data owned by someone else. When you get a reference, you get to look at it, maybe even mutate it, but once you are done with it (and you do have to be done with it, eventually) the owner gets control back. Rust has a bunch of rules in place to make sure that when you borrow a reference no one else mutates the referenced data, and part of the joy of Rust is learning to interpret the various reasons Rust won't let you do the things you wanted to do with references.

Let's investigate this 'joy' (50-50 sarcastic-serious, so single quotes) by trying to return *references* to key, value, and time data, rather than owned instances of these types.

```rust
pub trait Trace<Key: Ord, Val: Ord, Time: Lattice> {

	/// incorporates a new bunch of differences into the trace.
	fn add<Iter: Iterator<Item=(Key, Val, Time, isize)>(&mut self, diffs: Iter);

	/// An iterator defined by the implementation to produce results.
	type OutputIterator: Iterator<Item=(&Key, &Val, &Time, isize)>;

	/// retrieves differences associated with a specified key.
	fn get(&mut self, key: &Key) -> Self::OutputIterator;

}
```

We just put `&` in front of the results in the `OutputIterator` contraint. Aside: I didn't put a reference in front of the `isize` because we know we can always just copy that data.

This doesn't work, and Rust tries to help us out by saying:

	src/lib.rs:44:45: 44:49 error: missing lifetime specifier [E0106]
	src/lib.rs:44     type OutputIterator: Iterator<Item=(&Key, &Val, &Time, isize)>;
                                                          ^~~~
	src/lib.rs:44:45: 44:49 help: run `rustc --explain E0106` to see a detailed explanation

What is a lifetime specifier? You could totally run `rustc --explain E0106` to find out, and I was going to copy/paste it here but it is really quite long. Instead, I will try and explain.

Rust needs to be able to determine that references to the same data are not active at the same time, because that is what guarantees that no one is messing with your data while you are looking at it (or looking at your data while you mess with it). This is done through the concept of "lifetimes", an indication of "for how long" the reference is in play. Here "how long" is measured in "parts of your code" rather than something like real time.

For each reference you take, Rust infers the span of code for which the reference is live, and bakes that into the type. The problem here is that we haven't told Rust enough for it to figure out the lifetime for these references. Let's write something slightly less clever, but which shows where the lifetimes would come from; we will temporarily return to the more innocent time where we returned a `Vec` output rather than an iterator:

```rust
	/// retrieves differences associated with a specified key.
	fn get(&mut self, key: &Key) -> Vec<(&Key, &Val, &Time, isize)>;
```

This almost works. If it weren't for that `key` argument, Rust *would* be able to figure out the lifetimes of our outputs. 

Why? Because the only things the results could possibly refer *to* are the references supplied as inputs (or references available through them, transitively). What else could these reference possibly refer to that will still be valid after the method returns?

What is going on here, or would be going on without the `key` argument, is what Rust calls "lifetime elision", some handy rules Rust uses to remove the need to explicitly write lifetimes everywhere. But you can, and it is helpful to see to understand what Rust is actually doing. Let's fix that method up above with the right generic lifetimes:

```rust
	/// retrieves differences associated with a specified key.
	fn get<'a, 'b>(&'a mut self, key: &'b Key) -> Vec<(&'a Key, &'a Val, &'a Time, isize)>;
```

Whoooooaaaaa! All of the `&` things have some more noise around them! 

The most important thing to notice above is that `get` has two generic parameters, `'a` and `'b`, which are lifetime parameters. Their roles are to capture the lifetime information about the references supplied by the caller, and to say that in the vector of results, all those references have the same lifetime as the `self` reference rather than the `key` reference.

This makes a lot of sense, right? The references are totally into the trace, rather than at the query key. It's cool, all we need to do is tell Rust that. In exchange, Rust will make sure no one accidentally puts `key` into the result vector, as its referrent might get mutated or invalidated as we spin around a loop. 

You wouldn't do that, of course. I trust you, but Rust doesn't.

So, we need to put some `'a` things in front of our references to make Rust happy. For "reasons", we need to add it as a generic parameter for the trait, rather than the method. What reasons? Because the `OutputIterator` type constraint depends on `'a`, not just the `get` method, and Rust doesn't yet allow associated types to have generic parameters (part of "higher kinded types" or something).

```rust
pub trait Trace<'a, Key: Ord, Val: Ord, Time: Lattice> {

	/// incorporates a new bunch of differences into the trace.
	fn add<Iter: Iterator<Item=(Key, Val, Time, isize)>(&mut self, diffs: Iter);

	/// An iterator defined by the implementation to produce results.
	type OutputIterator: Iterator<Item=(&'a Key, &'a Val, &'a Time, isize)>;

	/// retrieves differences associated with a specified key.
	fn get(&'a mut self, key: &Key) -> Self::OutputIterator;

}
```

You might be a bit stressed that "how can we known which `'a` we will need" to which the answer is just "no worries, we'll implement the trait for all `'a`", which is a great thing that computers can do.

What is the last remaining issue? The types parameters `Key`, `Val`, and `Time` need some more constraints on them now. 

	src/lib.rs:33:1: 66:2 error: the parameter type `Key` may not live long enough [E0309]
	src/lib.rs:33 pub trait Trace<'a, Key: Ord, Val:Ord, Time: Lattice> {
	              ^
	src/lib.rs:33:1: 66:2 help: run `rustc --explain E0309` to see a detailed explanation
	src/lib.rs:33:1: 66:2 help: consider adding an explicit lifetime bound `Key: 'a`...
	src/lib.rs:33:1: 66:2 note: ...so that the type `Key` will meet its required lifetime bounds

What Rust is telling us now is that because we are thinking about returning types like `&'a Key` we have to promise that `Key` itself is actually valid for all of the lifetime `'a`. We could make `Key` something horrible like `&'b String` for some other `'b`, at which point the reference `&'a Key` wouldn't actually be to valid data. You probably weren't thinking you would do this, but Rust was. Rust is protecting you from weird creative you, and from your weird creative co-workers, and the weird creative unintended interactions of your code with theirs.

The fix is pretty simple:

```rust
pub trait Trace<'a, Key: Ord+'a, Val: Ord+'a, Time: Lattice+'a> {

	/// incorporates a new bunch of differences into the trace.
	fn add<Iter: Iterator<Item=(Key, Val, Time, isize)>(&mut self, diffs: Iter);

	/// An iterator defined by the implementation to produce results.
	type OutputIterator: Iterator<Item=(&'a Key, &'a Val, &'a Time, isize)>;

	/// retrieves differences associated with a specified key.
	fn get(&'a mut self, key: &Key) -> Self::OutputIterator;

}
```

The constraint `Key: Ord+'a` means that `Key` needs to implement `Ord` and live at least as long as `'a`, which mostly just means it can't contain references that might last less long. Typically `Key` is going to be some owned data like `u64` or `String` or even `Vec<Vec<Option<String>>>`, all of which satisfy this constraint.

### An observation

This whole section may give some insight into the Rust debugging process. We have done a lot of up-front work defining our trait, and scoping out several potential issues that Rust has already forced us to fix by making our method prototypes more specific. I would say that the majority of my time debugging Rust code is spent like this. I've literally spent zero time in an actual debugger, and once written while not necessarily correct, your code pretty much does what it says.

## Part 1: A very naïve version based on lists.

Coming soon!

## Part 2: Organizing the data into tries.

Coming later!

## Part 3: Adding an index.

Coming even later!