# Materialize and Arrangements

Arrangements are how Materialize stores data and maintains data as it changes.
They lie at the heart of what allows Materialize to efficiently maintain SQL views as data change.
At the same time, arrangements represent the core trade-off: they require memory to maintain, but save time for recomputation.
It is important to understand the details to make an informed choice, and to debug the memory utilization of your dataflows.

In this post, we will spell out the details of
1. what arrangements are,
2. where they get used in Materialize,
3. the resources they require, and
4. ways you can reduce the resource requirements.

By the end, you should be able to diagnose and improve the memory use of your materialized views!

## Some Shared Context

Before getting ahead of ourselves, we should establish some common vocabulary and context.

Materialize users currently enter queries as SQL.
There are many steps along the path from SQL operators to maintained arrangements.
SQL queries are transformed to a more structured tree of "expressions".
A forest of expressions is rendered to a dataflow of operators.
The underlying system executes and maintains dataflows of operators.
It is the last step, the maintenance of dataflows of operators, that require arrangements.

The steps from SQL query to maintained dataflow are many and changing.
Here, we will discuss the parts that are most directly connected: from expressions down to arrangements.
To inspect the expression associated with a query, you can always type
```
materialize> explain plan for <your select query>;
```
This will present the expression structure that would be rendered as dataflow.
The expressions announced in such a plan will directly lead to maintained arrangements.

## What are "arrangements"?

You can think of an arrangement as the streaming analogue of an "index" from a relational database.
An arrangement is a collection of data, indexed by a key, that is maintained as the underlying data change.
Several dataflow operators, like `Join` and `Reduce` require arrangements to function, and they will create them if they do not exist.
You can create arrangements yourself, like indexes, if you think they are likely to be re-used across multiple dataflows.

An arrangement maintains the data of the underlying collection in an indexed form.
Each arrangement is determined by an underlying data set, and some expressions that determine a "key" for each record.
The arrangement maintains a map from each key to records associated with it.
The size of an arrangement is roughly proportional to the number of distinct records in the underlying data set.

Operator for expressions such as `Join` and `Reduce` require arranged representations of their input to function.
If the appropriate arrangement does not exist, the operators will have to construct them before returning results.
Arrangements can be shared between operators that require the same arrangements (the same input and key).
Sharing arrangements reduces the resource requirements of dataflows, removing redundant memory and the compute required to maintain the memory.

## An Example: Joins

Let's consider a quick example to demonstrate where arrangements are used, and how sharing can help.

Imagine you are processing bank transactions, and you need to surface transactions between accounts in different countries.
We could imagine writing this as
```sql
-- transactions between countries.
select id, amount, source, target
from
    transaction,
    account as a_source,
    account as a_target
where
    transaction.source = a_source.id and
    transaction.target = a_target.id and
    a_source.country != a_target.country;
```
This query turns in to a three way join, between `transaction`, `account`, and `account` again.

Most likely, the query planner will plan this as a sequence of two binary joins.
First a binary join between `transaction` and `account`, followed by a second binary join between the results and `account` again.
Each of these two joins requires an arrangement on each of its inputs, each by the key used for the equijoin.

Materialize will make sure that each join input (there are four, two for each of the two binary joins) has an appropriate arrangement.
Although `account` is used twice in the query above, both times use the join uses the same key: the `id` field.
In this case, Materialize can re-use the `account` arrangement, reducing the resources required.

If this use case is representative, it may make sense to *pre-arrange* collections.
This allows Materialize to share arrangements *across* dataflows, rather than just within dataflows.
In this example, if `account` was pre-arranged by its `id` field, Materialize would only build two new arrangements.
If `transaction` was arranged by either its `source.id` or `target.id` columns, Materialize would only build one new arrangement.
If `transaction` was arranged by *both* its `source.id` and `target.id` columns, Materialize would build no new arrangements.
You can build a specific arrangement using the `CREATE INDEX` command.

## What Causes Arrangements to Exist?

Any Materialize command that creates a dataflow may cause arrangements to exist, until the dataflow concludes.
The command may instruct the system to build a specific arrangement, and will additionally require any arrangement the dataflow needs to maintain its subject.

The commands `CREATE MATERIALIZED SOURCE`, `CREATE MATERIALIZED VIEW`, and `CREATE INDEX` instruct Materialize to build and maintain arrangements for their subjects.
They will create dataflows (and potentially arrangements) that remain until the created item is dropped.
These commands should be judiciously invoked only on data that the user is comfortable maintaining in its entirety.

The commands `CREATE SINK` and `TAIL` will create dataflows but will not arrange their subjects.
The dataflows they create may require arrangements for their duration.

The command `SELECT` creates a dataflow to produce the answer to its query, but drops the dataflow as soon as the answer is produced.
It may require arrangements transiently, but their resources should be promptly released once the query returns.

> **TIP**: Consider restructing the use of the `MATERIALIZED` keyword to those views you plan to directly query.
> Materialize can often optimize your query plans to maintain less information for sources and views.
> By being clear about the first moment that you *require* materialization, you give the system more opportunities for optimization.

## Which Queries Require Arrangements?

Materialize will convert your SQL query into a dataflow computation, to efficiently maintain its contents.
The produced dataflow contains many "operators", many of which may require arrangements.
The easiest way to see which operators would result from a query is to use Materialize's `explain` command.
This command will produce a sequence of expressions that are used to implement your query.

For example, you could type:
```sql
materialize> explain plan for
-- transactions between countries.
select source, target, sum(amount) as total
from
    transaction,
    account as a_source,
    account as a_target
where
    transaction.source = a_source.id and
    transaction.target = a_target.id and
    a_source.country != a_target.country
group by
    source,
    target;
```
In response, Materialize might produce:
```
                    Optimized Plan
------------------------------------------------------
 %0 =                                                +
 | Get materialize.public.transaction (u5)           +
 | Filter !(isnull(#2)), !(isnull(#3))               +
                                                     +
 %1 =                                                +
 | Get materialize.public.account (u3)               +
 | ArrangeBy (#0)                                    +
                                                     +
 %2 =                                                +
 | Get materialize.public.account (u3)               +
 | ArrangeBy (#0)                                    +
                                                     +
 %3 =                                                +
 | Join %0 %1 %2 (= #2 #4) (= #3 #6)                 +
 | | implementation = Differential %0 %1.(#0) %2.(#0)+
 | | demand = (#1..#3, #5, #7)                       +
 | Filter !(isnull(#2)), !(isnull(#3)), (#5 != #7)   +
 | Reduce group=(#2, #3) sum(#1)                     +

(1 row)
```
This report is an implementation plan for your declarative SQL query.
It tells us what Materialize will actually make happen to implement your query.
It also tells us, indirectly, the arrangements your query will require.

The main expressions that require arrangements are `Join` and `Reduce`.
These expressions result respectively from SQL's various join operations and its group-by reduction.
There are other internal expressions that are less obviously connected to SQL you might type.
For example, the `TopK` expression is created if you have an `ORDER BY .. LIMIT ..` in a correlated subquery.
The `Threshold` expression is created if you use `EXCEPT ALL` or `INTERSECT ALL`.
The `ArrangeBy` expression is produced internally, and will create an arrangement if one does not exist.

Let's discuss each of these cases, recalling that the size of an arrangement is proportional to the distinct values it maintains.

### Stateless expressions

Many of the expressions in query plans do not require arrangements.
For example, the `Filter` expressions above can be applied record-by-record without retaining any historical state.
Materialize has many "stateless" expressions, including `Filter`, `Map`, `Project`, `Union`, `Negate`, `FlatMap`, `Get`, and `Let`.
These expressions do not require arrangements.
This is great news.

### Join Expressions

Materialize's `Join` expression describes a relational equijoin between multiple inputs.
Recall the `Join` expression from the example above:
```
 | Join %0 %1 %2 (= #2 #4) (= #3 #6)
 | | implementation = Differential %0 %1.(#0) %2.(#0)
 | | demand = (#1..#3, #5, #7)
```
Here, the join expression has three inputs, `%0 %1 %2`, which connect back to `transactions`, `accounts`, and `accounts` respectively.
The join expression also has equality constraints on its output columns, which it will implement among the sources.
But most importantly for us, the join plan announces a sequence of arrangements that it will require:
```
 | | implementation = Differential %0 %1.(#0) %2.(#0)
```
This line tells us that our plan is to start with `%0` and join with `%1` and then `%2`.
The parenthetical `(#0)` decorations indicate that those inputs should be arranged by their first column (`accounts.id`).

For this plan, Materialize will construct a dataflow that requires four arrangements, two each for each of the binary `Join` dataflow operators.
```
    %1 --> A1   %2 --> A2
             \           \
    %0 --> A0-Join --> A3-Join --> Out
```
The arrangements `A0`, `A1`, `A2` correspond to the three inputs.
The fourth arrangement, `A3`, corresponds to the results of the first binary join.

The arrangements `A0`, `A1`, `A2` may already exist, in which case Materialize will re-use them.
If an arrangement does not exist, which is the case at least for `A3`, Materialize will construct it.
When constructing a private arrangement, Materialize can optimize out rows and columns that are not needed.
Private arrangements can therefore be more efficient than a public shared arrangement, in principle.

---

In some case Materialize can create a join plan which creates no arrangements.
If all input collections are arranged by each of their primary and foreign keys, Materialize will use the `DeltaJoin` implementation.
This plan avoids arranging (and so maintaining) intermediate results, but uses more total arrangements.
If the necessary arrangements already exist, then this cost is small and the plan is appealing.

Informally, for each input Materialize constructs a dataflow specialized to that input.
For example, this fragment could be the dataflow for `0%`:
```
    %1 --> A1   %2 --> A2
             \           \
    %0 -----> Join -----> Join --> Out
```
Notice that neither `0%` nor the intermediate results are arranged.
The plan requires a dataflow like the above starting from each of the inputs.
The dataflows may require different arrangements for the same other inputs.
The total number of arrangements can be large, but often the arrangements already exist and can be re-used.

Delta joins are a useful way to minimize new arrangements, but they are also an advanced topic.
We will detail the delta join plan in a future post.

---

### Reduce expressions

Materialize's `Reduce` expressions mean to group records by a key and apply several reduction functions.
For example, it could group by three columns, and determine the sum of one expression, maximum of another, and count of distinct values of a third expression.
Consequently, a single `Reduce` expression results in a minor dataflow graph, rather than a single dataflow operator.
The structure of this dataflow graph is not finalized, and our discussion will instead be in broad strokes.
The `Reduce` expression should be rendered in a timely dataflow "region", which will organize the operators together.

The differential dataflow `Reduce` operator groups `(key, val)` records by `key` and applies a reduction function.
This operator requires an arrangement of its input, and produces an arrangement of its output.
Each use of this operator in the dataflow graph will require these two arrangements.

The `Reduce` expression may create multiple aggregations, each of which may have the `distinct` modifier.
Each of these aggregations may be rendered to independent dataflows, to avoid combinatorial explosion.
When the `distinct` modifier is present a differential dataflow `Reduce` operator is created for that purpose.
Operators like `min` and `max` may be turned in to a sequence of differential `Reduce` operators for performance reasons.

### TopK expressions

Materialize's `TopK` expression determines the top few records for each key, given key selecton expressions and ordering expressions.
Like the `min` and `max` reductions above, this expression is implemented in a sequence of differential `Reduce` operators.
Each operator applies the logic to progressively coarser groupings, arriving at the keys themselves.
Each of the operators in this sequence must maintain an arrangement for its input and output.

### Threshold expressions

Materialize's `Threshold` expression is applied to a collection that may have negative accumulations to ensure all accumulations are non-negative.
It uses a differential dataflow `Reduce` operator to do this, and so arranges its input and its output.

## Diagnosing Arrangement Use.

Materialize maintains substantial information about its arrangements, their sizes, and their re-use across dataflows.
This information can be invaluable in diagnosing and improving the memory use of your queries.

To get a report of the arrangements Materialize maintains, you can type
```
materialize=> select * from mz_arrangement_sizes;
```
At the moment, this returns
```
materialize=> select * from mz_arrangement_sizes order by operator;
 operator | worker | records | batches
----------+--------+---------+---------
      201 |      0 |       0 |       1
      212 |      0 |      24 |       2
      216 |      0 |       0 |       1
      229 |      0 |      10 |       2
      233 |      0 |       0 |       1
      246 |      0 |      58 |       3
      250 |      0 |       0 |       1
      263 |      0 |       0 |       1
      267 |      0 |       0 |       1
      280 |      0 |       0 |       1
      284 |      0 |       0 |       1
      297 |      0 |       1 |       2
      301 |      0 |       0 |       1
      314 |      0 |       4 |       2
      318 |      0 |       0 |       1
      331 |      0 |     118 |       4
      335 |      0 |       0 |       1
      348 |      0 |       0 |       1
      352 |      0 |       0 |       1
      365 |      0 |       0 |       1
      369 |      0 |       0 |       1
(21 rows)
```

The `operator` and `worker` columns name timely dataflow operators and threads.
The `records` and `batches` columns report the numbers of records grouped in some number of batches.
In this example, many of the results are zero, as there are no records maintained.

To name the operators associated with the arrangements, we could join with `mz_dataflow_operators`:
```
materialize=> select * from mz_arrangement_sizes mas, mz_dataflow_operators mdo where mas.operator = mdo.id and mas.worker = mdo.worker order by operator;
 operator | worker | records | batches | id  | worker |      name
----------+--------+---------+---------+-----+--------+----------------
      212 |      0 |      24 |       2 | 212 |      0 | Arrange
      216 |      0 |       0 |       1 | 216 |      0 | Arrange-errors
      229 |      0 |      10 |       2 | 229 |      0 | Arrange
      233 |      0 |       0 |       1 | 233 |      0 | Arrange-errors
      246 |      0 |      58 |       3 | 246 |      0 | Arrange
      250 |      0 |       0 |       1 | 250 |      0 | Arrange-errors
      263 |      0 |       0 |       1 | 263 |      0 | Arrange
      267 |      0 |       0 |       1 | 267 |      0 | Arrange-errors
      280 |      0 |       0 |       1 | 280 |      0 | Arrange
      284 |      0 |       0 |       1 | 284 |      0 | Arrange-errors
      297 |      0 |       1 |       2 | 297 |      0 | Arrange
      301 |      0 |       0 |       1 | 301 |      0 | Arrange-errors
      314 |      0 |       4 |       2 | 314 |      0 | Arrange
      318 |      0 |       0 |       1 | 318 |      0 | Arrange-errors
      331 |      0 |     118 |       4 | 331 |      0 | Arrange
      335 |      0 |       0 |       1 | 335 |      0 | Arrange-errors
      348 |      0 |       0 |       1 | 348 |      0 | Arrange
      352 |      0 |       0 |       1 | 352 |      0 | Arrange-errors
      365 |      0 |       0 |       1 | 365 |      0 | Arrange
      369 |      0 |       0 |       1 | 369 |      0 | Arrange-errors
(20 rows)
```

These arrangements are not especially well named.
Materialize independently maintains data and errors for each collection.
These arrangements are for system views, which we can recover from the `mz_dataflow_operators_dataflows` collection.
```
materialize=> select * from mz_dataflow_operator_dataflows order by id;
```
The results are substantially larger, as they contain all operators not only those with arrangements.

Another option are to use the system views `mz_records_per_dataflow_operator` and `mz_records_per_dataflow` which perform this work for you.
```
materialize=> select * from mz_records_per_dataflow;
 id  |                         name                          | worker | records
-----+-------------------------------------------------------+--------+---------
 306 | Dataflow: mz_catalog.mz_schemas_primary_idx           |      0 |       4
 323 | Dataflow: mz_catalog.mz_columns_primary_idx           |      0 |     118
 289 | Dataflow: mz_catalog.mz_databases_primary_idx         |      0 |       1
 204 | Dataflow: mz_catalog.mz_view_keys_primary_idx         |      0 |      24
 255 | Dataflow: mz_catalog.mz_kafka_sinks_primary_idx       |      0 |       0
 357 | Dataflow: materialize.public.account_primary_idx      |      0 |       0
 238 | Dataflow: mz_catalog.mz_catalog_names_primary_idx     |      0 |      58
 272 | Dataflow: mz_catalog.mz_avro_ocf_sinks_primary_idx    |      0 |       0
 340 | Dataflow: materialize.public.transaction_primary_idx  |      0 |       0
 221 | Dataflow: mz_catalog.mz_view_foreign_keys_primary_idx |      0 |      10
(10 rows)
```

### Creating a New Dataflow

Let's install a dataflow to maintain the bank transfer view up above, and see what happens.

First, I'll create two tables to act as sources of data.
```
materialize=> create table transaction (id int, amount int, source int, target int);
materialize=> create table account (id int, country int);
```
<!-- Consider making this SQL copy-paste friendly (i.e., remove the `materialize->` prefixes). -->
Now, we create a materialized view for our query
```sql
materialize=> create materialized view transfers as
materialize-> select source, target, sum(amount) as total
materialize-> from
materialize->     transaction,
materialize->     account as a_source,
materialize->     account as a_target
materialize-> where
materialize->     transaction.source = a_source.id and
materialize->     transaction.target = a_target.id and
materialize->     a_source.country != a_target.country
materialize-> group by
materialize->     source,
materialize->     target;
```
If we consult `mz_records_per_dataflow`, we now see a new entry
```
materialize=> select * from mz_records_per_dataflow order by id;
  id  |                         name                          | worker | records
------+-------------------------------------------------------+--------+---------
  204 | Dataflow: mz_catalog.mz_view_keys_primary_idx         |      0 |      24
  221 | Dataflow: mz_catalog.mz_view_foreign_keys_primary_idx |      0 |      10
  238 | Dataflow: mz_catalog.mz_catalog_names_primary_idx     |      0 |      60
  255 | Dataflow: mz_catalog.mz_kafka_sinks_primary_idx       |      0 |       0
  272 | Dataflow: mz_catalog.mz_avro_ocf_sinks_primary_idx    |      0 |       0
  289 | Dataflow: mz_catalog.mz_databases_primary_idx         |      0 |       1
  306 | Dataflow: mz_catalog.mz_schemas_primary_idx           |      0 |       4
  323 | Dataflow: mz_catalog.mz_columns_primary_idx           |      0 |     121
  340 | Dataflow: materialize.public.transaction_primary_idx  |      0 |       0
  357 | Dataflow: materialize.public.account_primary_idx      |      0 |       0
 1772 | Dataflow: materialize.public.transfers_primary_idx    |      0 |       0
(11 rows)
```
There are no records there, but we can certainly see a new entry for our `transfers` view.

We can now investigate `mz_arrangement_sizes`, ordering by `operator` to see our new operators at the end.
```
materialize=> select * from mz_arrangement_sizes mas, mz_dataflow_operators mdo where mas.operator = mdo.id and mas.worker = mdo.worker order by operator;
 operator | worker | records | batches
----------+--------+---------+---------
<<REMOVED FOR CLARITY>>
     1803 |      0 |       0 |       1 | 1803 |      0 | Arrange
     1823 |      0 |       0 |       1 | 1823 |      0 | Arrange
     1844 |      0 |       0 |       1 | 1844 |      0 | JoinStage: 1
     1879 |      0 |       0 |       1 | 1879 |      0 | Arrange
     1881 |      0 |       0 |       1 | 1881 |      0 | ReduceAccumulable
     1885 |      0 |       0 |       1 | 1885 |      0 | Arrange
(26 rows)
```
As you can see, we have six new arrangements.
It turns out, these are three arrangements for the join (one arrangement can be re-used) and three arrangements for the reduce (the last bonus arrangement holds any errors that could result from expression evaluation in `Reduce`).

## Improving Resource Use

Materialize will happily use the memory you instruct it to use, as you supply it with queries and data.
In many cases it has techniques it can apply to reduce the memory footprint, but it may also need your help.
Let's talk through a few examples where you can reframe the query to reduce the amount of memory required.

### Inspect query plans

Materialize's `explain plan for <query>` command will report how your query would be implemented.
These plans are one of the first places to look if your query uses more resources than you expect.
In particular, see if you can recognize your original query structure in the plans, and identify the role of each stateful expression.
For each stateful expression, determine if you believe the accumulated input should be reasonable (the implementation will maintain this accumulated input).

If any of these steps fail, it may be important to reframe your query (and perhaps file bugs against Materialize's query planning).

### Simplifying Queries

Several operators are suprisingly easy to type, but expensive to implement.
The `UNION` operator in SQL is more expensive than the `UNION ALL`  operator, because it needs to de-duplicate records.
`LEFT JOIN` and other outer joins need to maintain additional state to track which keys went unmatched in the join.
Correlated subqueries have similar complexity to outer joins.
These operators have complex implementations because they must defend against peculiarities of the data that you may not worry about.

In these cases, you may benefit from manually translating your query to a similar query with simpler operators.

* Consider using `UNION ALL` instead of `UNION` when you do not require deduplication, or are certain that there is no duplication to remove.
* Consider replacing outer joins with inner joins, and tracking the unmatched records separately.
* Consider manually decorrelating any correlated subqueries, if the plan seem more complex than you expect.

### Reduction pushdown

Idiomatic SQL has you write queries that join relations and then reduce the result with a `group by`.
In many cases, the `group by` reduction could be performed before the join.
For example, our `transfers` view above could be rewritten to pre-aggregate the transactions between accounts first.
```sql
-- transactions between countries.
select source, target, total
from
    (   -- aggregate transactions first
        select source, target, sum(amount) as total
        from transaction
        group by source, target
    ) as transaction_agg,
    account as a_source,
    account as a_target
where
    transaction_agg.source = a_source.id and
    transaction_agg.target = a_target.id and
    a_source.country != a_target.country
```
This transformation performs the reduction first, and then joins with `account` twice to determine if the result should be surfaced.
This new query may maintain substantially less state in the arrangements used by the join:
instead of maintaining each distinct `amount` as a separate record, we reduce the data to at most one record for each `(source, target)` pair.

This transformation is only valid if `account.id` is a unique key:
if multiple records could have the same `id`, the sum could multiply by each pair of mis-matched countries.
You might not have thought of that, but Materialize has and can not apply this transformation automatically.
This is a great opportunity for you to explain that you are comfortable with the more efficient query.

### Ask Questions

If you think that your query could be more efficiently maintained, please reach out and ask us!
There are often optimizations we have overlooked, or special cases that we did not appreciate.
Alternately, we may be able to explain why an optimization is not generally valid, but how to transform your specific query.
